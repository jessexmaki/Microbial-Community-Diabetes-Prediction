{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc5xkI2hXrwh"
      },
      "source": [
        "# Microbial Community Disease Risk Prediction\n",
        "\n",
        "In this case study, we develop and evaluate neural network models to predict disease risk from high-dimensional microbiome sequence data. Our dataset consists of 16S rRNA gene profiles from 16,344 stool samples, with approximately half of the samples coming from individuals diagnosed with type 1 diabetes (cases) and the other half from individuals without a diagnosis of type 1 diabetes (controls). By modeling patterns in these microbial community profiles, our goal is to accurately classify samples based on disease status. This could provide insight into whether an individual's gut microbiome composition is associated with their risk of developing type 1 diabetes. We implement and compare several neural network architectures, including convolutional and recurrent networks, to evaluate their ability to capture predictive signals from large-scale marker gene surveys of complex microbial communities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "alDR3GTbXqOw",
        "outputId": "ce196825-e15c-4f06-ebfb-b2ca4f477c23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DTA0</th>\n",
              "      <th>DTA1</th>\n",
              "      <th>DTA2</th>\n",
              "      <th>DTA3</th>\n",
              "      <th>DTA4</th>\n",
              "      <th>DTA5</th>\n",
              "      <th>DTA6</th>\n",
              "      <th>DTA7</th>\n",
              "      <th>DTA8</th>\n",
              "      <th>DTA9</th>\n",
              "      <th>...</th>\n",
              "      <th>DTA247</th>\n",
              "      <th>DTA248</th>\n",
              "      <th>DTA249</th>\n",
              "      <th>DTA250</th>\n",
              "      <th>DTA251</th>\n",
              "      <th>DTA252</th>\n",
              "      <th>DTA253</th>\n",
              "      <th>DTA254</th>\n",
              "      <th>DTA255</th>\n",
              "      <th>LBL0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.92</td>\n",
              "      <td>1.80</td>\n",
              "      <td>1.44</td>\n",
              "      <td>1.79</td>\n",
              "      <td>1.68</td>\n",
              "      <td>1.42</td>\n",
              "      <td>1.52</td>\n",
              "      <td>1.58</td>\n",
              "      <td>1.43</td>\n",
              "      <td>1.45</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.02</td>\n",
              "      <td>-2.32</td>\n",
              "      <td>-2.19</td>\n",
              "      <td>-2.25</td>\n",
              "      <td>-2.25</td>\n",
              "      <td>-2.29</td>\n",
              "      <td>-2.19</td>\n",
              "      <td>-2.63</td>\n",
              "      <td>-2.86</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.97</td>\n",
              "      <td>1.98</td>\n",
              "      <td>2.16</td>\n",
              "      <td>2.12</td>\n",
              "      <td>1.78</td>\n",
              "      <td>1.71</td>\n",
              "      <td>1.69</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.74</td>\n",
              "      <td>1.64</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.05</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>-1.92</td>\n",
              "      <td>-2.12</td>\n",
              "      <td>-1.94</td>\n",
              "      <td>-2.18</td>\n",
              "      <td>-2.45</td>\n",
              "      <td>-2.63</td>\n",
              "      <td>-2.87</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.25</td>\n",
              "      <td>2.11</td>\n",
              "      <td>2.05</td>\n",
              "      <td>1.92</td>\n",
              "      <td>2.08</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.87</td>\n",
              "      <td>1.57</td>\n",
              "      <td>1.81</td>\n",
              "      <td>1.61</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.02</td>\n",
              "      <td>-1.87</td>\n",
              "      <td>-1.95</td>\n",
              "      <td>-2.09</td>\n",
              "      <td>-1.96</td>\n",
              "      <td>-1.99</td>\n",
              "      <td>-2.01</td>\n",
              "      <td>-2.57</td>\n",
              "      <td>-2.71</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.25</td>\n",
              "      <td>2.07</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.84</td>\n",
              "      <td>1.83</td>\n",
              "      <td>1.80</td>\n",
              "      <td>1.88</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.70</td>\n",
              "      <td>1.46</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.94</td>\n",
              "      <td>-2.11</td>\n",
              "      <td>-2.22</td>\n",
              "      <td>-1.98</td>\n",
              "      <td>-2.22</td>\n",
              "      <td>-2.00</td>\n",
              "      <td>-2.10</td>\n",
              "      <td>-2.59</td>\n",
              "      <td>-2.84</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.28</td>\n",
              "      <td>2.27</td>\n",
              "      <td>2.26</td>\n",
              "      <td>2.20</td>\n",
              "      <td>2.01</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.99</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.68</td>\n",
              "      <td>1.79</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.69</td>\n",
              "      <td>-1.66</td>\n",
              "      <td>-1.82</td>\n",
              "      <td>-1.88</td>\n",
              "      <td>-1.92</td>\n",
              "      <td>-1.89</td>\n",
              "      <td>-2.07</td>\n",
              "      <td>-2.50</td>\n",
              "      <td>-2.72</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 257 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   DTA0  DTA1  DTA2  DTA3  DTA4  DTA5  DTA6  DTA7  DTA8  DTA9  ...  DTA247   \n",
              "0  1.92  1.80  1.44  1.79  1.68  1.42  1.52  1.58  1.43  1.45  ...   -2.02  \\\n",
              "1  1.97  1.98  2.16  2.12  1.78  1.71  1.69  1.60  1.74  1.64  ...   -2.05   \n",
              "2  2.25  2.11  2.05  1.92  2.08  1.93  1.87  1.57  1.81  1.61  ...   -2.02   \n",
              "3  2.25  2.07  1.92  1.84  1.83  1.80  1.88  1.48  1.70  1.46  ...   -1.94   \n",
              "4  2.28  2.27  2.26  2.20  2.01  2.00  1.99  1.92  1.68  1.79  ...   -1.69   \n",
              "\n",
              "   DTA248  DTA249  DTA250  DTA251  DTA252  DTA253  DTA254  DTA255  LBL0  \n",
              "0   -2.32   -2.19   -2.25   -2.25   -2.29   -2.19   -2.63   -2.86   1.0  \n",
              "1   -1.97   -1.92   -2.12   -1.94   -2.18   -2.45   -2.63   -2.87   0.0  \n",
              "2   -1.87   -1.95   -2.09   -1.96   -1.99   -2.01   -2.57   -2.71   1.0  \n",
              "3   -2.11   -2.22   -1.98   -2.22   -2.00   -2.10   -2.59   -2.84   0.0  \n",
              "4   -1.66   -1.82   -1.88   -1.92   -1.89   -2.07   -2.50   -2.72   0.0  \n",
              "\n",
              "[5 rows x 257 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "dataframe = pandas.read_csv('https://raw.githubusercontent.com/bryankolaczkowski/ALS3200C/main/mbiome.data.csv')\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlKLWh5rXq9g"
      },
      "source": [
        "The dataset contains 256 columns labeled DTA0 through DTA255, representing the relative abundances of 256 bacterial taxa across the 16,344 samples. Relative abundance is calculated as the proportion of sequencing reads assigned to each taxon in a given sample. To account for sequencing depth differences, the relative abundances have been normalized using a center log-ratio transformation - a standard technique for compositional microbial data. This transforms the data to a log scale centered at zero, where positive values indicate higher than average abundance, and negative values indicate lower than average abundance for a given taxon. After transformation, the relative abundance values typically range from +2.5 to -2.5.\n",
        "\n",
        "The target prediction variable is contained in the LBL0 column, with 0 indicating control samples and 1 indicating case samples positive for type 1 diabetes. Our modeling goal is to accurately predict this disease label based on the multivariate microbial community profiles in columns DTA0 through DTA255.\n",
        "\n",
        "We first split the data into training and validation subsets for model fitting and evaluation. We then extract the DTA columns as model inputs and the LBL0 column as labels. To leverage TensorFlow's sequence modeling capabilities, we expand the data to three dimensions, with the additional dimension representing the ordered sequence of taxa.\n",
        "\n",
        "In the following sections, we fit and compare several neural network architectures, including convolutional and recurrent networks, to evaluate their ability to capture predictive signals about disease status from the full set of microbial taxa abundances and their co-occurrence patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVTUJdVQYDkv",
        "outputId": "f43085fa-0e91-4750-ebba-d93aecf1bab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13075, 257) (3269, 257) (16344, 257)\n",
            "(13075, 256, 1) (3269, 256, 1)\n",
            "(13075,) (3269,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# create train-validate split\n",
        "train_dataframe = dataframe.sample(frac=0.8, random_state=2100963)\n",
        "valid_dataframe = dataframe.drop(train_dataframe.index)\n",
        "print(train_dataframe.shape, valid_dataframe.shape, dataframe.shape)\n",
        "\n",
        "# extract explanatory variables\n",
        "dta_ids = [ x for x in dataframe.columns if x.find('DTA') == 0 ]\n",
        "train_x = np.expand_dims(train_dataframe[dta_ids].to_numpy(), axis=-1)\n",
        "valid_x = np.expand_dims(valid_dataframe[dta_ids].to_numpy(), axis=-1)\n",
        "print(train_x.shape, valid_x.shape)\n",
        "\n",
        "# extract labels\n",
        "train_y = train_dataframe['LBL0'].to_numpy()\n",
        "valid_y = valid_dataframe['LBL0'].to_numpy()\n",
        "print(train_y.shape, valid_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8CPzypUY4TL"
      },
      "source": [
        "We can see that there are 16,344 total samples in our dataframe. We've extracted 13,057 for training and 3,269 for validation.\n",
        "\n",
        "After expanding the data dimension, we have explanatory variables of shape (256,1), a one-dimensional sequence of 256 bacterial 'species'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYabR-E7fsni"
      },
      "source": [
        "## simple linear model\n",
        "\n",
        "Now that we have some training and validation data, we just need to build a classifier to predict disease risk from the data.\n",
        "\n",
        "First, we'll start with a simple linear model implemented using a single Dense neuron with sigmoid output, as this is a binary classification problem.\n",
        "\n",
        "In previous cases, we were able to send the data directly to the Dense layer. But in this case, because we have 'expanded' the last dimension of the data - in order to fit tensorflow's sequence models - we need to 'collapse' that dimension back down, so it can be properly analyzed by the Dense layer.\n",
        "\n",
        "It's pretty easy to do this; we just need to use a Flatten layer to 'flatten' the 'expanded' data back down to a simple vector. And, because the Flatten layer is just like any other tensorflow Layer object, we can use it as the *first* layer in our network, provided we set the input_shape option.\n",
        "\n",
        "The following code cell implements a simple linear classifier for our disease-risk prediction problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldKzbLpyXIAW",
        "outputId": "bbf531eb-c53e-40ef-ee61-20854f4deff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 257 (1.00 KB)\n",
            "Trainable params: 257 (1.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "409/409 [==============================] - 2s 4ms/step - loss: 0.6910 - accuracy: 0.5468 - val_loss: 0.6895 - val_accuracy: 0.5216\n",
            "Epoch 2/20\n",
            "409/409 [==============================] - 2s 6ms/step - loss: 0.6686 - accuracy: 0.6028 - val_loss: 0.6711 - val_accuracy: 0.5418\n",
            "Epoch 3/20\n",
            "409/409 [==============================] - 1s 3ms/step - loss: 0.6516 - accuracy: 0.6481 - val_loss: 0.6547 - val_accuracy: 0.5702\n",
            "Epoch 4/20\n",
            "409/409 [==============================] - 1s 4ms/step - loss: 0.6359 - accuracy: 0.6823 - val_loss: 0.6396 - val_accuracy: 0.6020\n",
            "Epoch 5/20\n",
            "409/409 [==============================] - 1s 4ms/step - loss: 0.6214 - accuracy: 0.7112 - val_loss: 0.6257 - val_accuracy: 0.6357\n",
            "Epoch 6/20\n",
            "409/409 [==============================] - 1s 4ms/step - loss: 0.6080 - accuracy: 0.7310 - val_loss: 0.6128 - val_accuracy: 0.6614\n",
            "Epoch 7/20\n",
            "409/409 [==============================] - 2s 4ms/step - loss: 0.5955 - accuracy: 0.7473 - val_loss: 0.6008 - val_accuracy: 0.6852\n",
            "Epoch 8/20\n",
            "409/409 [==============================] - 2s 4ms/step - loss: 0.5839 - accuracy: 0.7595 - val_loss: 0.5898 - val_accuracy: 0.7011\n",
            "Epoch 9/20\n",
            "409/409 [==============================] - 1s 4ms/step - loss: 0.5732 - accuracy: 0.7689 - val_loss: 0.5795 - val_accuracy: 0.7177\n",
            "Epoch 10/20\n",
            "409/409 [==============================] - 1s 4ms/step - loss: 0.5631 - accuracy: 0.7769 - val_loss: 0.5699 - val_accuracy: 0.7296\n",
            "Epoch 11/20\n",
            "409/409 [==============================] - 1s 3ms/step - loss: 0.5537 - accuracy: 0.7814 - val_loss: 0.5609 - val_accuracy: 0.7391\n",
            "Epoch 12/20\n",
            "409/409 [==============================] - 2s 4ms/step - loss: 0.5450 - accuracy: 0.7857 - val_loss: 0.5526 - val_accuracy: 0.7476\n",
            "Epoch 13/20\n",
            "409/409 [==============================] - 1s 3ms/step - loss: 0.5368 - accuracy: 0.7907 - val_loss: 0.5447 - val_accuracy: 0.7562\n",
            "Epoch 14/20\n",
            "409/409 [==============================] - 1s 4ms/step - loss: 0.5290 - accuracy: 0.7936 - val_loss: 0.5374 - val_accuracy: 0.7617\n",
            "Epoch 15/20\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.5218 - accuracy: 0.7972 - val_loss: 0.5305 - val_accuracy: 0.7684\n",
            "Epoch 16/20\n",
            "409/409 [==============================] - 2s 4ms/step - loss: 0.5150 - accuracy: 0.8008 - val_loss: 0.5241 - val_accuracy: 0.7727\n",
            "Epoch 17/20\n",
            "409/409 [==============================] - 1s 3ms/step - loss: 0.5086 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7770\n",
            "Epoch 18/20\n",
            "409/409 [==============================] - 2s 4ms/step - loss: 0.5025 - accuracy: 0.8060 - val_loss: 0.5122 - val_accuracy: 0.7791\n",
            "Epoch 19/20\n",
            "409/409 [==============================] - 2s 5ms/step - loss: 0.4968 - accuracy: 0.8078 - val_loss: 0.5068 - val_accuracy: 0.7822\n",
            "Epoch 20/20\n",
            "409/409 [==============================] - 1s 4ms/step - loss: 0.4914 - accuracy: 0.8099 - val_loss: 0.5017 - val_accuracy: 0.7856\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78333012c910>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# download data\n",
        "dataframe = pandas.read_csv('https://raw.githubusercontent.com/bryankolaczkowski/ALS3200C/main/mbiome.data.csv')\n",
        "\n",
        "# create train-validate split\n",
        "train_dataframe = dataframe.sample(frac=0.8, random_state=2100963)\n",
        "valid_dataframe = dataframe.drop(train_dataframe.index)\n",
        "\n",
        "# extract explanatory variables\n",
        "dta_ids = [ x for x in dataframe.columns if x.find('DTA') == 0 ]\n",
        "train_x = np.expand_dims(train_dataframe[dta_ids].to_numpy(), axis=-1)\n",
        "valid_x = np.expand_dims(valid_dataframe[dta_ids].to_numpy(), axis=-1)\n",
        "\n",
        "# extract labels\n",
        "train_y = train_dataframe['LBL0'].to_numpy()\n",
        "valid_y = valid_dataframe['LBL0'].to_numpy()\n",
        "\n",
        "# package data into tensorflow dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(32)\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y)).batch(32)\n",
        "\n",
        "# build model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(256,1)))\n",
        "model.add(tf.keras.layers.Dense(units=1, activation=tf.keras.activations.sigmoid))\n",
        "model.summary()\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "model.fit(train_data, epochs=20, validation_data=valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAKPoof9XyDd"
      },
      "source": [
        "Our initial baseline model is a simple linear classifier with only 257 trainable parameters - 256 input weights plus a single bias term. Despite its simplicity, it achieves solid performance, reaching approximately 80% training accuracy and 78% validation accuracy after 20 epochs. This indicates that a substantial amount of predictive signal for the disease labels is contained in a linear combination of the microbial taxa abundances. The linear model provides a reasonable baseline to benchmark more complex nonlinear models against. We now explore whether convolutional and recurrent neural network architectures can capture higher-order nonlinear relationships and covariation in the community structure to improve classification accuracy beyond this linear baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqMA5a8V_eMI"
      },
      "source": [
        "## convolution model\n",
        "\n",
        "In the next code section, we implement a basic one-layer convolutional neural network for disease classification. The convolution layer consists of 16 filters of length 3 applied with same padding, such that the output sequence length remains 256. We use a tanh activation, which is less common than ReLU for modern convnets but allows for more direct comparison to the default activation in recurrent networks. With 4,161 trainable weights, this nonlinear model has substantially more parameters than the linear baseline. To account for this increased model capacity, we train for 50 epochs which is longer than the linear model. This convolution network allows us to model localized nonlinear interactions among adjacent taxa in the community profiles. We can evaluate whether directly capturing these short-range taxon co-occurrence patterns improves predictive performance beyond the linear model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93rSQ41XYduw",
        "outputId": "c8af18fb-0795-4f34-cb73-3cbfb5f97661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 256, 16)           64        \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4161 (16.25 KB)\n",
            "Trainable params: 4161 (16.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "409/409 [==============================] - 1s 1ms/step - loss: 0.6752 - accuracy: 0.5778 - val_loss: 0.6363 - val_accuracy: 0.7167\n",
            "Epoch 2/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.6747 - val_loss: 0.5996 - val_accuracy: 0.6455\n",
            "Epoch 3/50\n",
            "409/409 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7339 - val_loss: 0.5484 - val_accuracy: 0.7222\n",
            "Epoch 4/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7623 - val_loss: 0.5200 - val_accuracy: 0.7485\n",
            "Epoch 5/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7798 - val_loss: 0.4999 - val_accuracy: 0.7589\n",
            "Epoch 6/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7920 - val_loss: 0.4843 - val_accuracy: 0.7645\n",
            "Epoch 7/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7998 - val_loss: 0.4722 - val_accuracy: 0.7687\n",
            "Epoch 8/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.8059 - val_loss: 0.4628 - val_accuracy: 0.7749\n",
            "Epoch 9/50\n",
            "409/409 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.8121 - val_loss: 0.4553 - val_accuracy: 0.7816\n",
            "Epoch 10/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8149 - val_loss: 0.4491 - val_accuracy: 0.7822\n",
            "Epoch 11/50\n",
            "409/409 [==============================] - 1s 1ms/step - loss: 0.4165 - accuracy: 0.8180 - val_loss: 0.4439 - val_accuracy: 0.7862\n",
            "Epoch 12/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8199 - val_loss: 0.4396 - val_accuracy: 0.7895\n",
            "Epoch 13/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8220 - val_loss: 0.4359 - val_accuracy: 0.7920\n",
            "Epoch 14/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.4022 - accuracy: 0.8236 - val_loss: 0.4328 - val_accuracy: 0.7941\n",
            "Epoch 15/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8238 - val_loss: 0.4301 - val_accuracy: 0.7954\n",
            "Epoch 16/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3952 - accuracy: 0.8247 - val_loss: 0.4277 - val_accuracy: 0.7981\n",
            "Epoch 17/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8253 - val_loss: 0.4256 - val_accuracy: 0.7987\n",
            "Epoch 18/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.8264 - val_loss: 0.4238 - val_accuracy: 0.8002\n",
            "Epoch 19/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8272 - val_loss: 0.4221 - val_accuracy: 0.8024\n",
            "Epoch 20/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3851 - accuracy: 0.8276 - val_loss: 0.4206 - val_accuracy: 0.8042\n",
            "Epoch 21/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8278 - val_loss: 0.4193 - val_accuracy: 0.8039\n",
            "Epoch 22/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8288 - val_loss: 0.4180 - val_accuracy: 0.8033\n",
            "Epoch 23/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8298 - val_loss: 0.4169 - val_accuracy: 0.8045\n",
            "Epoch 24/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8301 - val_loss: 0.4158 - val_accuracy: 0.8051\n",
            "Epoch 25/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8321 - val_loss: 0.4148 - val_accuracy: 0.8054\n",
            "Epoch 26/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.8328 - val_loss: 0.4138 - val_accuracy: 0.8064\n",
            "Epoch 27/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8337 - val_loss: 0.4129 - val_accuracy: 0.8067\n",
            "Epoch 28/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8343 - val_loss: 0.4120 - val_accuracy: 0.8076\n",
            "Epoch 29/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8347 - val_loss: 0.4112 - val_accuracy: 0.8082\n",
            "Epoch 30/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8350 - val_loss: 0.4104 - val_accuracy: 0.8079\n",
            "Epoch 31/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8354 - val_loss: 0.4096 - val_accuracy: 0.8076\n",
            "Epoch 32/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8354 - val_loss: 0.4088 - val_accuracy: 0.8073\n",
            "Epoch 33/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8356 - val_loss: 0.4080 - val_accuracy: 0.8073\n",
            "Epoch 34/50\n",
            "409/409 [==============================] - 1s 1ms/step - loss: 0.3672 - accuracy: 0.8359 - val_loss: 0.4073 - val_accuracy: 0.8073\n",
            "Epoch 35/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8360 - val_loss: 0.4066 - val_accuracy: 0.8073\n",
            "Epoch 36/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8362 - val_loss: 0.4059 - val_accuracy: 0.8070\n",
            "Epoch 37/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8367 - val_loss: 0.4052 - val_accuracy: 0.8097\n",
            "Epoch 38/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8374 - val_loss: 0.4045 - val_accuracy: 0.8094\n",
            "Epoch 39/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3638 - accuracy: 0.8373 - val_loss: 0.4038 - val_accuracy: 0.8100\n",
            "Epoch 40/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8374 - val_loss: 0.4031 - val_accuracy: 0.8106\n",
            "Epoch 41/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8375 - val_loss: 0.4025 - val_accuracy: 0.8110\n",
            "Epoch 42/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8385 - val_loss: 0.4018 - val_accuracy: 0.8122\n",
            "Epoch 43/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8390 - val_loss: 0.4012 - val_accuracy: 0.8116\n",
            "Epoch 44/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8391 - val_loss: 0.4006 - val_accuracy: 0.8125\n",
            "Epoch 45/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8395 - val_loss: 0.3999 - val_accuracy: 0.8134\n",
            "Epoch 46/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8395 - val_loss: 0.3993 - val_accuracy: 0.8137\n",
            "Epoch 47/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8398 - val_loss: 0.3987 - val_accuracy: 0.8134\n",
            "Epoch 48/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8397 - val_loss: 0.3981 - val_accuracy: 0.8143\n",
            "Epoch 49/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8399 - val_loss: 0.3975 - val_accuracy: 0.8155\n",
            "Epoch 50/50\n",
            "409/409 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8402 - val_loss: 0.3969 - val_accuracy: 0.8165\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2c2333250>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# download data\n",
        "dataframe = pandas.read_csv('https://raw.githubusercontent.com/bryankolaczkowski/ALS3200C/main/mbiome.data.csv')\n",
        "\n",
        "# create train-validate split\n",
        "train_dataframe = dataframe.sample(frac=0.8, random_state=2100963)\n",
        "valid_dataframe = dataframe.drop(train_dataframe.index)\n",
        "\n",
        "# extract explanatory variables\n",
        "dta_ids = [ x for x in dataframe.columns if x.find('DTA') == 0 ]\n",
        "train_x = np.expand_dims(train_dataframe[dta_ids].to_numpy(), axis=-1)\n",
        "valid_x = np.expand_dims(valid_dataframe[dta_ids].to_numpy(), axis=-1)\n",
        "\n",
        "# extract labels\n",
        "train_y = train_dataframe['LBL0'].to_numpy()\n",
        "valid_y = valid_dataframe['LBL0'].to_numpy()\n",
        "\n",
        "# package data into tensorflow dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(32)\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y)).batch(32)\n",
        "\n",
        "# build model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv1D(filters=16,\n",
        "                                 kernel_size=(3,),\n",
        "                                 activation=tf.keras.activations.tanh,\n",
        "                                 padding='same',\n",
        "                                 input_shape=(256,1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=1, activation=tf.keras.activations.sigmoid))\n",
        "model.summary()\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "model.fit(train_data, epochs=50, validation_data=valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4ZyqiR5BWOx"
      },
      "source": [
        "## LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijrxhUsmZXtB",
        "outputId": "17e8c8ba-7174-42c2-d5f9-3d8e748d3194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 256, 16)           1152      \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5249 (20.50 KB)\n",
            "Trainable params: 5249 (20.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "409/409 [==============================] - 11s 25ms/step - loss: 0.6791 - accuracy: 0.5606 - val_loss: 0.6420 - val_accuracy: 0.7054\n",
            "Epoch 2/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.6165 - accuracy: 0.6766 - val_loss: 0.6013 - val_accuracy: 0.6601\n",
            "Epoch 3/50\n",
            "409/409 [==============================] - 11s 27ms/step - loss: 0.5451 - accuracy: 0.7407 - val_loss: 0.5271 - val_accuracy: 0.7443\n",
            "Epoch 4/50\n",
            "409/409 [==============================] - 11s 26ms/step - loss: 0.4920 - accuracy: 0.7725 - val_loss: 0.5017 - val_accuracy: 0.7489\n",
            "Epoch 5/50\n",
            "409/409 [==============================] - 10s 26ms/step - loss: 0.4624 - accuracy: 0.7846 - val_loss: 0.4892 - val_accuracy: 0.7525\n",
            "Epoch 6/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.4431 - accuracy: 0.7966 - val_loss: 0.4839 - val_accuracy: 0.7571\n",
            "Epoch 7/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.4292 - accuracy: 0.8054 - val_loss: 0.4808 - val_accuracy: 0.7620\n",
            "Epoch 8/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.4764 - val_accuracy: 0.7675\n",
            "Epoch 9/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.4092 - accuracy: 0.8163 - val_loss: 0.4726 - val_accuracy: 0.7715\n",
            "Epoch 10/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.4027 - accuracy: 0.8187 - val_loss: 0.4724 - val_accuracy: 0.7730\n",
            "Epoch 11/50\n",
            "409/409 [==============================] - 10s 24ms/step - loss: 0.3977 - accuracy: 0.8215 - val_loss: 0.4731 - val_accuracy: 0.7721\n",
            "Epoch 12/50\n",
            "409/409 [==============================] - 10s 24ms/step - loss: 0.3935 - accuracy: 0.8236 - val_loss: 0.4739 - val_accuracy: 0.7733\n",
            "Epoch 13/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3901 - accuracy: 0.8251 - val_loss: 0.4746 - val_accuracy: 0.7749\n",
            "Epoch 14/50\n",
            "409/409 [==============================] - 11s 26ms/step - loss: 0.3871 - accuracy: 0.8268 - val_loss: 0.4750 - val_accuracy: 0.7767\n",
            "Epoch 15/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3845 - accuracy: 0.8270 - val_loss: 0.4751 - val_accuracy: 0.7758\n",
            "Epoch 16/50\n",
            "409/409 [==============================] - 11s 26ms/step - loss: 0.3822 - accuracy: 0.8282 - val_loss: 0.4749 - val_accuracy: 0.7767\n",
            "Epoch 17/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3801 - accuracy: 0.8292 - val_loss: 0.4744 - val_accuracy: 0.7776\n",
            "Epoch 18/50\n",
            "409/409 [==============================] - 11s 26ms/step - loss: 0.3782 - accuracy: 0.8297 - val_loss: 0.4737 - val_accuracy: 0.7779\n",
            "Epoch 19/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3764 - accuracy: 0.8298 - val_loss: 0.4728 - val_accuracy: 0.7801\n",
            "Epoch 20/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3747 - accuracy: 0.8307 - val_loss: 0.4717 - val_accuracy: 0.7816\n",
            "Epoch 21/50\n",
            "409/409 [==============================] - 11s 26ms/step - loss: 0.3730 - accuracy: 0.8311 - val_loss: 0.4706 - val_accuracy: 0.7837\n",
            "Epoch 22/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3715 - accuracy: 0.8312 - val_loss: 0.4694 - val_accuracy: 0.7862\n",
            "Epoch 23/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3700 - accuracy: 0.8324 - val_loss: 0.4682 - val_accuracy: 0.7868\n",
            "Epoch 24/50\n",
            "409/409 [==============================] - 11s 26ms/step - loss: 0.3686 - accuracy: 0.8332 - val_loss: 0.4671 - val_accuracy: 0.7892\n",
            "Epoch 25/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3672 - accuracy: 0.8337 - val_loss: 0.4660 - val_accuracy: 0.7889\n",
            "Epoch 26/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3659 - accuracy: 0.8350 - val_loss: 0.4649 - val_accuracy: 0.7901\n",
            "Epoch 27/50\n",
            "409/409 [==============================] - 11s 26ms/step - loss: 0.3647 - accuracy: 0.8361 - val_loss: 0.4638 - val_accuracy: 0.7911\n",
            "Epoch 28/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3635 - accuracy: 0.8369 - val_loss: 0.4627 - val_accuracy: 0.7911\n",
            "Epoch 29/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3623 - accuracy: 0.8372 - val_loss: 0.4616 - val_accuracy: 0.7926\n",
            "Epoch 30/50\n",
            "409/409 [==============================] - 11s 28ms/step - loss: 0.3612 - accuracy: 0.8379 - val_loss: 0.4604 - val_accuracy: 0.7935\n",
            "Epoch 31/50\n",
            "409/409 [==============================] - 11s 26ms/step - loss: 0.3601 - accuracy: 0.8385 - val_loss: 0.4591 - val_accuracy: 0.7935\n",
            "Epoch 32/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3591 - accuracy: 0.8392 - val_loss: 0.4578 - val_accuracy: 0.7935\n",
            "Epoch 33/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3581 - accuracy: 0.8404 - val_loss: 0.4565 - val_accuracy: 0.7941\n",
            "Epoch 34/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3571 - accuracy: 0.8410 - val_loss: 0.4551 - val_accuracy: 0.7938\n",
            "Epoch 35/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3562 - accuracy: 0.8421 - val_loss: 0.4538 - val_accuracy: 0.7947\n",
            "Epoch 36/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3553 - accuracy: 0.8426 - val_loss: 0.4524 - val_accuracy: 0.7966\n",
            "Epoch 37/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3545 - accuracy: 0.8433 - val_loss: 0.4510 - val_accuracy: 0.7978\n",
            "Epoch 38/50\n",
            "409/409 [==============================] - 10s 24ms/step - loss: 0.3537 - accuracy: 0.8439 - val_loss: 0.4496 - val_accuracy: 0.7975\n",
            "Epoch 39/50\n",
            "409/409 [==============================] - 10s 24ms/step - loss: 0.3529 - accuracy: 0.8445 - val_loss: 0.4482 - val_accuracy: 0.7984\n",
            "Epoch 40/50\n",
            "409/409 [==============================] - 10s 24ms/step - loss: 0.3521 - accuracy: 0.8445 - val_loss: 0.4469 - val_accuracy: 0.8002\n",
            "Epoch 41/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3514 - accuracy: 0.8447 - val_loss: 0.4455 - val_accuracy: 0.8002\n",
            "Epoch 42/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3507 - accuracy: 0.8447 - val_loss: 0.4441 - val_accuracy: 0.8018\n",
            "Epoch 43/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3500 - accuracy: 0.8450 - val_loss: 0.4427 - val_accuracy: 0.8018\n",
            "Epoch 44/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3493 - accuracy: 0.8449 - val_loss: 0.4413 - val_accuracy: 0.8024\n",
            "Epoch 45/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3487 - accuracy: 0.8451 - val_loss: 0.4398 - val_accuracy: 0.8033\n",
            "Epoch 46/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3480 - accuracy: 0.8454 - val_loss: 0.4384 - val_accuracy: 0.8045\n",
            "Epoch 47/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3474 - accuracy: 0.8460 - val_loss: 0.4370 - val_accuracy: 0.8064\n",
            "Epoch 48/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3468 - accuracy: 0.8458 - val_loss: 0.4356 - val_accuracy: 0.8073\n",
            "Epoch 49/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3463 - accuracy: 0.8461 - val_loss: 0.4342 - val_accuracy: 0.8085\n",
            "Epoch 50/50\n",
            "409/409 [==============================] - 10s 25ms/step - loss: 0.3457 - accuracy: 0.8459 - val_loss: 0.4329 - val_accuracy: 0.8088\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2c561ac10>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# download data\n",
        "dataframe = pandas.read_csv('https://raw.githubusercontent.com/bryankolaczkowski/ALS3200C/main/mbiome.data.csv')\n",
        "\n",
        "# create train-validate split\n",
        "train_dataframe = dataframe.sample(frac=0.8, random_state=2100963)\n",
        "valid_dataframe = dataframe.drop(train_dataframe.index)\n",
        "\n",
        "# extract explanatory variables\n",
        "dta_ids = [ x for x in dataframe.columns if x.find('DTA') == 0 ]\n",
        "train_x = np.expand_dims(train_dataframe[dta_ids].to_numpy(), axis=-1)\n",
        "valid_x = np.expand_dims(valid_dataframe[dta_ids].to_numpy(), axis=-1)\n",
        "\n",
        "# extract labels\n",
        "train_y = train_dataframe['LBL0'].to_numpy()\n",
        "valid_y = valid_dataframe['LBL0'].to_numpy()\n",
        "\n",
        "# package data into tensorflow dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(32)\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y)).batch(32)\n",
        "\n",
        "# build model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(units=16, return_sequences=True, input_shape=(256,1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=1, activation=tf.keras.activations.sigmoid))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "model.fit(train_data, epochs=50, validation_data=valid_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "name": "microbiome.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
